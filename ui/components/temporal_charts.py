# FICHIER COMPLET: temporal_charts.py avec TOUTES les fonctions existantes + filtres
# Remplacez tout le contenu de votre fichier temporal_charts.py par ce code

import streamlit as st
import pandas as pd
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from typing import List, Dict, Optional, Tuple
import re


# ===== NOUVELLE FONCTION PRINCIPALE AVEC SUPPORT DES FILTRES =====
def render_temporal_performance(data, date_range=None, campaign_types_data=None):
    """
    Fonction principale am√©lior√©e qui d√©tecte si les filtres sont disponibles
    et utilise la version appropri√©e

    Args:
        data: DataFrame consolid√©
        date_range: Tuple optionnel (date_debut, date_fin)
        campaign_types_data: DataFrame optionnel avec les classifications
    """
    # Si les param√®tres de filtrage sont fournis, utiliser la version avec filtres
    if date_range is not None or campaign_types_data is not None:
        # Assurer que date_range existe
        if date_range is None:
            if 'date' in data.columns:
                date_range = (data['date'].min(), data['date'].max())
            else:
                date_range = (pd.Timestamp.now() - pd.Timedelta(days=30), pd.Timestamp.now())

        # Appeler la version avec filtres
        render_temporal_performance_with_filters(data, date_range, campaign_types_data)
    else:
        # Sinon, utiliser la version originale
        render_temporal_performance_original(data)


# ===== VERSION ORIGINALE (votre code actuel) =====
def render_temporal_performance_original(data):
    """Version originale de la fonction sans filtres"""
    st.subheader("üìä Performances Journali√®res")

    # Grouper par date - inclure toutes les m√©triques n√©cessaires
    daily_data = data.groupby('date').agg({
        'cost': 'sum',
        'impressions': 'sum',
        'clicks': 'sum',
        'installs': 'sum',
        'purchases': 'sum',
        'login': 'sum',
        'revenue': 'sum'
    }).reset_index()

    daily_data['date'] = pd.to_datetime(daily_data['date'])
    daily_data = daily_data.sort_values('date')

    # Calcul des m√©triques d√©riv√©es
    daily_data['cpi'] = daily_data['cost'] / daily_data['installs'].replace(0, 1)
    daily_data['roas'] = daily_data['revenue'] / daily_data['cost'].replace(0, 1)

    # Remplacer les valeurs infinies par 0
    daily_data['cpi'] = daily_data['cpi'].replace([float('inf'), -float('inf')], 0)
    daily_data['roas'] = daily_data['roas'].replace([float('inf'), -float('inf')], 0)

    # ============ GRAPHIQUES PRINCIPAUX (4 existants) ============
    fig_main = make_subplots(
        rows=2, cols=2,
        subplot_titles=('Co√ªt', 'Impressions', 'Clics', 'Installations'),
        specs=[[{"secondary_y": False}, {"secondary_y": False}],
               [{"secondary_y": False}, {"secondary_y": False}]]
    )

    # Co√ªt
    fig_main.add_trace(
        go.Scatter(x=daily_data['date'], y=daily_data['cost'],
                   name='Co√ªt', line=dict(color='#e74c3c')),
        row=1, col=1
    )

    # Impressions
    fig_main.add_trace(
        go.Scatter(x=daily_data['date'], y=daily_data['impressions'],
                   name='Impressions', line=dict(color='#3498db')),
        row=1, col=2
    )

    # Clics
    fig_main.add_trace(
        go.Scatter(x=daily_data['date'], y=daily_data['clicks'],
                   name='Clics', line=dict(color='#2ecc71')),
        row=2, col=1
    )

    # Installations
    fig_main.add_trace(
        go.Scatter(x=daily_data['date'], y=daily_data['installs'],
                   name='Installations', line=dict(color='#9b59b6')),
        row=2, col=2
    )

    fig_main.update_layout(
        height=600,
        showlegend=False
    )

    st.plotly_chart(fig_main, use_container_width=True)

    # ============ NOUVEAUX GRAPHIQUES (5 nouveaux) ============

    # Premi√®re ligne : Purchases, Logins, Revenu
    fig_secondary_1 = make_subplots(
        rows=1, cols=3,
        subplot_titles=('Purchases', 'Logins', 'Revenu'),
        specs=[[{"secondary_y": False}, {"secondary_y": False}, {"secondary_y": False}]]
    )

    # Purchases
    fig_secondary_1.add_trace(
        go.Scatter(x=daily_data['date'], y=daily_data['purchases'],
                   name='Purchases', line=dict(color='#f39c12')),
        row=1, col=1
    )

    # Logins
    fig_secondary_1.add_trace(
        go.Scatter(x=daily_data['date'], y=daily_data['login'],
                   name='Logins', line=dict(color='#1abc9c')),
        row=1, col=2
    )

    # Revenu
    fig_secondary_1.add_trace(
        go.Scatter(x=daily_data['date'], y=daily_data['revenue'],
                   name='Revenu', line=dict(color='#27ae60')),
        row=1, col=3
    )

    fig_secondary_1.update_layout(
        height=400,
        showlegend=False
    )

    st.plotly_chart(fig_secondary_1, use_container_width=True)

    # Deuxi√®me ligne : CPI et ROAS
    # REMPLACEZ TOUTE CETTE SECTION :

    # V√©rifier quel type de campagnes on affiche
    fig_secondary_2 = make_subplots(
        rows=1, cols=2,
        subplot_titles=('CPI' if has_installs else 'CPA', 'ROAS'),
        specs=[[{"secondary_y": False}, {"secondary_y": False}]]
    )

    # Premier graphique : CPI ou CPA selon le type
    if has_installs and 'cpi' in daily_data.columns:
        fig_secondary_2.add_trace(
            go.Scatter(x=daily_data['date'], y=daily_data['cpi'],
                       name='CPI', line=dict(color='#e67e22')),
            row=1, col=1
        )
    elif 'cpa' in daily_data.columns:
        fig_secondary_2.add_trace(
            go.Scatter(x=daily_data['date'], y=daily_data['cpa'],
                       name='CPA', line=dict(color='#e67e22')),
            row=1, col=1
        )

    # ROAS
    if 'roas' in daily_data.columns:
        fig_secondary_2.add_trace(
            go.Scatter(x=daily_data['date'], y=daily_data['roas'],
                       name='ROAS', line=dict(color='#8e44ad')),
            row=1, col=2
        )

    fig_secondary_2.update_layout(
        height=400,
        showlegend=False
    )

    st.plotly_chart(fig_secondary_2, use_container_width=True)


# ===== NOUVELLE VERSION AVEC FILTRES =====
def render_temporal_performance_with_filters(data: pd.DataFrame, date_range: Tuple,
                                             campaign_types_data: Optional[pd.DataFrame] = None):
    """
    Version am√©lior√©e avec filtres avanc√©s pour les performances journali√®res
    """
    st.subheader("üìä Performances Journali√®res")

    # ===== SECTION FILTRES AVANC√âS =====
    with st.expander("üîß Filtres Avanc√©s", expanded=False):
        col1, col2, col3 = st.columns([2, 2, 1])

        with col1:
            st.markdown("**üîç Filtrage par Nom de Campagne**")

            # Mode de filtrage
            filter_mode = st.radio(
                "Mode de filtrage",
                options=["Inclusion", "Exclusion"],
                horizontal=True,
                key="temporal_filter_mode",
                help="Inclusion = garder seulement les campagnes qui matchent | Exclusion = retirer les campagnes qui matchent"
            )

            # Pattern regex
            regex_pattern = st.text_input(
                "Pattern Regex",
                value="",
                placeholder="Ex: SEA.*FR|App.*iOS|Top.*Destinations",
                key="temporal_regex_pattern",
                help="Utilisez | pour 'OU', .* pour 'n'importe quoi', ^ pour d√©but, $ pour fin"
            )

            # Validation regex
            regex_valid = True
            if regex_pattern:
                try:
                    re.compile(regex_pattern)
                    st.success("‚úÖ Regex valide")
                except re.error as e:
                    st.error(f"‚ùå Regex invalide: {e}")
                    regex_valid = False

        with col2:
            st.markdown("**üè∑Ô∏è Filtrage par Type et Canal**")

            # Types de campagne disponibles
            available_types = ["branding", "acquisition", "retargeting"]
            if campaign_types_data is not None and not campaign_types_data.empty:
                if 'campaign_type' in campaign_types_data.columns:
                    types_in_data = campaign_types_data['campaign_type'].dropna().unique().tolist()
                    if types_in_data:
                        available_types = types_in_data

            selected_types = st.multiselect(
                "Type de campagne",
                options=available_types,
                default=[],
                key="temporal_campaign_types",
                help="Laissez vide pour inclure tous les types"
            )

            # Canaux disponibles
            available_channels = ["app", "web"]
            if campaign_types_data is not None and not campaign_types_data.empty:
                if 'platform_type' in campaign_types_data.columns:
                    channels_in_data = campaign_types_data['platform_type'].dropna().unique().tolist()
                    if channels_in_data:
                        available_channels = channels_in_data

            selected_channels = st.multiselect(
                "Canal",
                options=available_channels,
                default=[],
                key="temporal_channels",
                help="Laissez vide pour inclure tous les canaux"
            )

        with col3:
            st.markdown("**üìÖ P√©riode Rapide**")

            period_select = st.selectbox(
                "S√©lection rapide",
                options=["Tout", "7 derniers jours", "14 derniers jours", "30 derniers jours", "Mois en cours"],
                key="temporal_period_select"
            )

    # ===== APPLICATION DES FILTRES =====
    filtered_data = apply_temporal_filters(
        data=data,
        campaign_types_data=campaign_types_data,
        regex_pattern=regex_pattern if regex_valid else "",
        filter_mode=filter_mode.lower(),
        selected_types=selected_types,
        selected_channels=selected_channels,
        period_select=period_select,
        date_range=date_range
    )

    # ===== AFFICHAGE DU R√âSUM√â DES FILTRES =====
    if regex_pattern or selected_types or selected_channels or period_select != "Tout":
        with st.container():
            st.markdown("---")

            col_summary1, col_summary2, col_summary3, col_summary4 = st.columns(4)

            with col_summary1:
                if regex_pattern and regex_valid:
                    st.info(f"üîç Regex ({filter_mode}): `{regex_pattern}`")

            with col_summary2:
                if selected_types:
                    st.info(f"üè∑Ô∏è Types: {', '.join(selected_types)}")

            with col_summary3:
                if selected_channels:
                    st.info(f"üì± Canaux: {', '.join(selected_channels)}")

            with col_summary4:
                if period_select != "Tout":
                    st.info(f"üìÖ P√©riode: {period_select}")

            # M√©triques de filtrage
            # M√©triques de filtrage
            st.markdown("")
            metric_col1, metric_col2, metric_col3, metric_col4, metric_col5, metric_col6 = st.columns(6)

            with metric_col1:
                nb_campaigns = filtered_data[
                    'campaign_name'].nunique() if 'campaign_name' in filtered_data.columns else 0
                st.metric("Campagnes filtr√©es", f"{nb_campaigns}")

            with metric_col2:
                nb_days = filtered_data['date'].nunique() if 'date' in filtered_data.columns else 0
                st.metric("Jours affich√©s", f"{nb_days}")

            with metric_col3:
                total_cost = filtered_data['cost'].sum() if 'cost' in filtered_data.columns else 0
                st.metric("Co√ªt total", f"{total_cost:,.0f}‚Ç¨")

            with metric_col4:
                total_revenue = filtered_data['revenue'].sum() if 'revenue' in filtered_data.columns else 0
                st.metric("Revenu total", f"{total_revenue:,.0f}‚Ç¨")

            with metric_col5:
                total_purchases = filtered_data['purchases'].sum() if 'purchases' in filtered_data.columns else 0
                total_installs = filtered_data['installs'].sum() if 'installs' in filtered_data.columns else 0
                total_login = filtered_data['login'].sum() if 'login' in filtered_data.columns else 0

                # Afficher soit installs (pour App) soit purchases (pour Web) selon ce qui est pertinent
                if total_installs > 0:
                    st.metric("Installs/Logins", f"{total_installs:.0f}/{total_login:.0f}")
                else:
                    st.metric("Purchases", f"{total_purchases:.0f}")

            with metric_col6:
                # Calculer le ROAS
                roas = (total_revenue / total_cost) if total_cost > 0 else 0
                st.metric("ROAS", f"{roas:.2f}")

            st.markdown("---")

    # ===== AFFICHAGE DES GRAPHIQUES (r√©utilisation du code existant) =====
    if filtered_data.empty:
        st.warning("üîç Aucune donn√©e trouv√©e avec les filtres appliqu√©s")
        return

    # Grouper par date
    daily_data = filtered_data.groupby('date').agg({
        'cost': 'sum',
        'impressions': 'sum',
        'clicks': 'sum',
        'installs': 'sum',
        'purchases': 'sum',
        'login': 'sum',
        'revenue': 'sum'
    }).reset_index()

    daily_data['date'] = pd.to_datetime(daily_data['date'])
    daily_data = daily_data.sort_values('date')

    # PAR :
    has_installs = daily_data['installs'].sum() > 0

    if has_installs:
        # Pour App : calculer CPI
        daily_data['cpi'] = daily_data['cost'] / daily_data['installs'].replace(0, 1)
        daily_data['cpi'] = daily_data['cpi'].replace([float('inf'), -float('inf')], 0)
    else:
        # Pour Web : calculer CPA
        daily_data['cpa'] = daily_data['cost'] / daily_data['purchases'].replace(0, 1)
        daily_data['cpa'] = daily_data['cpa'].replace([float('inf'), -float('inf')], 0)

    # ROAS se calcule toujours
    daily_data['roas'] = daily_data['revenue'] / daily_data['cost'].replace(0, 1)
    daily_data['roas'] = daily_data['roas'].replace([float('inf'), -float('inf')], 0)

    # Graphiques principaux (4 graphiques)
    fig_main = make_subplots(
        rows=2, cols=2,
        subplot_titles=('Co√ªt', 'Impressions', 'Clics', 'Installations'),
        specs=[[{"secondary_y": False}, {"secondary_y": False}],
               [{"secondary_y": False}, {"secondary_y": False}]]
    )

    fig_main.add_trace(
        go.Scatter(x=daily_data['date'], y=daily_data['cost'],
                   name='Co√ªt', line=dict(color='#e74c3c')),
        row=1, col=1
    )

    fig_main.add_trace(
        go.Scatter(x=daily_data['date'], y=daily_data['impressions'],
                   name='Impressions', line=dict(color='#3498db')),
        row=1, col=2
    )

    fig_main.add_trace(
        go.Scatter(x=daily_data['date'], y=daily_data['clicks'],
                   name='Clics', line=dict(color='#2ecc71')),
        row=2, col=1
    )

    fig_main.add_trace(
        go.Scatter(x=daily_data['date'], y=daily_data['installs'],
                   name='Installations', line=dict(color='#9b59b6')),
        row=2, col=2
    )

    fig_main.update_layout(height=600, showlegend=False)
    st.plotly_chart(fig_main, use_container_width=True)

    # Graphiques secondaires (Purchases, Logins, Revenu)
    fig_secondary_1 = make_subplots(
        rows=1, cols=3,
        subplot_titles=('Purchases', 'Logins', 'Revenu'),
        specs=[[{"secondary_y": False}, {"secondary_y": False}, {"secondary_y": False}]]
    )

    fig_secondary_1.add_trace(
        go.Scatter(x=daily_data['date'], y=daily_data['purchases'],
                   name='Purchases', line=dict(color='#f39c12')),
        row=1, col=1
    )

    fig_secondary_1.add_trace(
        go.Scatter(x=daily_data['date'], y=daily_data['login'],
                   name='Logins', line=dict(color='#1abc9c')),
        row=1, col=2
    )

    fig_secondary_1.add_trace(
        go.Scatter(x=daily_data['date'], y=daily_data['revenue'],
                   name='Revenu', line=dict(color='#27ae60')),
        row=1, col=3
    )

    fig_secondary_1.update_layout(height=400, showlegend=False)
    st.plotly_chart(fig_secondary_1, use_container_width=True)

    # Graphiques CPI et ROAS
    fig_secondary_2 = make_subplots(
        rows=1, cols=2,
        subplot_titles=('CPI', 'ROAS'),
        specs=[[{"secondary_y": False}, {"secondary_y": False}]]
    )

    fig_secondary_2.add_trace(
        go.Scatter(x=daily_data['date'], y=daily_data['cpi'],
                   name='CPI', line=dict(color='#e67e22')),
        row=1, col=1
    )

    fig_secondary_2.add_trace(
        go.Scatter(x=daily_data['date'], y=daily_data['roas'],
                   name='ROAS', line=dict(color='#8e44ad')),
        row=1, col=2
    )

    fig_secondary_2.update_layout(height=400, showlegend=False)
    st.plotly_chart(fig_secondary_2, use_container_width=True)


def apply_temporal_filters(
        data: pd.DataFrame,
        campaign_types_data: Optional[pd.DataFrame],
        regex_pattern: str,
        filter_mode: str,
        selected_types: list,
        selected_channels: list,
        period_select: str,
        date_range: tuple
) -> pd.DataFrame:
    """
    Applique tous les filtres sur les donn√©es pour les performances temporelles
    Version compl√®te avec normalisation des colonnes et debug
    """
    filtered = data.copy()

    # DEBUG : V√©rifier les donn√©es re√ßues
    print(f"üîç DEBUG apply_temporal_filters:")
    print(f"   - Lignes re√ßues: {len(filtered)}")
    print(f"   - Colonnes disponibles: {filtered.columns.tolist()[:15]}...")

    # ===== NORMALISATION DES COLONNES =====
    # Mapping pour normaliser les noms de colonnes (notamment pour ASA)
    column_mapping = {
        'Campaign Name': 'campaign_name',
        'Campaign': 'campaign_name',
        'campaign': 'campaign_name',
        'Day': 'date',
        'Date': 'date',
        'day': 'date',
        'Spend': 'cost',
        'Cost': 'cost',
        'spend': 'cost',
        'Taps': 'clicks',
        'Clicks': 'clicks',
        'taps': 'clicks',
        'Installs (Tap-Through)': 'installs',
        'Installs': 'installs',
        'installs (tap-through)': 'installs',
        'New Downloads (Tap-Through)': 'new_downloads',
        'Redownloads (Tap-Through)': 'redownloads',
        'Impressions': 'impressions',
        'Impr.': 'impressions',
        'Purchase': 'purchases',
        'Purchases': 'purchases',
        'Revenue': 'revenue',
        'Conv. value': 'revenue',
        'Unified revenue': 'revenue',
        'Unified installs': 'installs',
        'Unified purchases': 'purchases',
        'Unified opens': 'opens',
        'Unified login': 'login'
    }

    # Appliquer le mapping de colonnes
    for old_name, new_name in column_mapping.items():
        if old_name in filtered.columns and new_name not in filtered.columns:
            filtered.rename(columns={old_name: new_name}, inplace=True)
            print(f"   - Renomm√©: {old_name} ‚Üí {new_name}")

    # ===== V√âRIFICATION ET CR√âATION DES COLONNES ESSENTIELLES =====

    # V√©rifier campaign_name
    if 'campaign_name' not in filtered.columns:
        print("‚ö†Ô∏è Colonne campaign_name manquante apr√®s normalisation")
        # Essayer de trouver une alternative
        possible_campaign_cols = [col for col in filtered.columns if 'campaign' in col.lower()]
        if possible_campaign_cols:
            filtered['campaign_name'] = filtered[possible_campaign_cols[0]]
            print(f"   - Utilis√© {possible_campaign_cols[0]} comme campaign_name")
        else:
            filtered['campaign_name'] = 'Unknown'
            print("   - Cr√©√© campaign_name avec valeur par d√©faut 'Unknown'")

    # S'assurer que les colonnes num√©riques sont bien num√©riques
    numeric_columns = ['cost', 'clicks', 'impressions', 'installs', 'purchases', 'revenue', 'opens', 'login']
    for col in numeric_columns:
        if col in filtered.columns:
            filtered[col] = pd.to_numeric(filtered[col], errors='coerce').fillna(0)

    # Cr√©er les colonnes manquantes avec des valeurs par d√©faut
    if 'opens' not in filtered.columns:
        filtered['opens'] = 0
    if 'login' not in filtered.columns:
        filtered['login'] = 0
    if 'revenue' not in filtered.columns:
        filtered['revenue'] = 0
    if 'purchases' not in filtered.columns:
        filtered['purchases'] = 0

    # Stats avant filtrage
    print(f"   - Campagnes uniques: {filtered['campaign_name'].nunique()}")
    print(f"   - Exemples campagnes: {filtered['campaign_name'].unique()[:5].tolist()}")
    print(f"   - Co√ªt total avant filtrage: {filtered['cost'].sum():.2f}‚Ç¨" if 'cost' in filtered.columns else "")

    # ===== 1. ENRICHISSEMENT AVEC CLASSIFICATIONS =====
    if campaign_types_data is not None and not campaign_types_data.empty:
        if 'campaign_name' in filtered.columns and 'campaign_name' in campaign_types_data.columns:
            print(f"   - Fusion avec classifications...")

            # Pr√©parer les classifications
            classifications = campaign_types_data[['campaign_name', 'campaign_type', 'platform_type']].drop_duplicates()

            # Merger avec les classifications
            before_merge = len(filtered)
            filtered = filtered.merge(
                classifications,
                on='campaign_name',
                how='left',
                suffixes=('', '_class')
            )
            print(f"   - Lignes apr√®s merge: {before_merge} ‚Üí {len(filtered)}")

            # G√©rer les colonnes de classification dupliqu√©es
            if 'campaign_type_class' in filtered.columns:
                if 'campaign_type' not in filtered.columns:
                    filtered['campaign_type'] = filtered['campaign_type_class']
                else:
                    filtered['campaign_type'] = filtered['campaign_type'].fillna(filtered['campaign_type_class'])
                filtered = filtered.drop(columns=['campaign_type_class'])

            if 'platform_type_class' in filtered.columns:
                if 'platform_type' not in filtered.columns:
                    filtered['platform_type'] = filtered['platform_type_class']
                else:
                    filtered['platform_type'] = filtered['platform_type'].fillna(filtered['platform_type_class'])
                filtered = filtered.drop(columns=['platform_type_class'])

    # ===== 2. FILTRE REGEX SUR NOM DE CAMPAGNE =====
    if regex_pattern and 'campaign_name' in filtered.columns:
        try:
            print(f"   - Application regex '{regex_pattern}' en mode {filter_mode}")
            pattern = re.compile(regex_pattern, re.IGNORECASE)

            # Cr√©er le masque
            mask = filtered['campaign_name'].str.contains(pattern, na=False, regex=True)
            matches = mask.sum()

            print(f"   - Campagnes qui matchent le pattern: {matches}/{len(mask)}")

            # Afficher quelques exemples de campagnes qui matchent
            if matches > 0:
                matching_campaigns = filtered[mask]['campaign_name'].unique()[:3]
                print(f"   - Exemples de matches: {matching_campaigns.tolist()}")

            # Appliquer le filtre selon le mode
            if filter_mode == 'inclusion':
                filtered = filtered[mask]
                print(f"   ‚úÖ Apr√®s inclusion: {len(filtered)} lignes gard√©es")
            else:  # exclusion
                filtered = filtered[~mask]
                print(f"   ‚úÖ Apr√®s exclusion: {len(filtered)} lignes gard√©es")

        except re.error as e:
            print(f"   ‚ùå Erreur regex: {e}")

    # ===== 3. FILTRE SUR TYPE DE CAMPAGNE =====
    if selected_types and 'campaign_type' in filtered.columns:
        print(f"   - Filtre par types: {selected_types}")
        before = len(filtered)
        filtered = filtered[filtered['campaign_type'].isin(selected_types)]
        print(f"   ‚úÖ Apr√®s filtre types: {before} ‚Üí {len(filtered)} lignes")

    # ===== 4. FILTRE SUR CANAL =====
    if selected_channels:
        print(f"   - Filtre par canaux: {selected_channels}")

        # Identifier la colonne canal
        channel_column = None
        if 'platform_type' in filtered.columns:
            channel_column = 'platform_type'
        elif 'channel_type' in filtered.columns:
            channel_column = 'channel_type'
        elif 'platform' in filtered.columns:
            channel_column = 'platform'

        if channel_column:
            before = len(filtered)
            filtered = filtered[filtered[channel_column].isin(selected_channels)]
            print(f"   ‚úÖ Apr√®s filtre canaux ({channel_column}): {before} ‚Üí {len(filtered)} lignes")
        else:
            print(f"   ‚ö†Ô∏è Pas de colonne canal trouv√©e")

    # ===== 5. FILTRE DE P√âRIODE =====
    if period_select != "Tout" and 'date' in filtered.columns:
        print(f"   - Filtre p√©riode: {period_select}")

        # S'assurer que la colonne date est en datetime
        filtered['date'] = pd.to_datetime(filtered['date'], errors='coerce')

        # Retirer les lignes avec dates invalides
        before_date_filter = len(filtered)
        filtered = filtered[filtered['date'].notna()]
        if before_date_filter > len(filtered):
            print(f"   - {before_date_filter - len(filtered)} lignes retir√©es (dates invalides)")

        # Calculer la p√©riode
        end_date = pd.Timestamp(date_range[1])

        if period_select == "7 derniers jours":
            start_date = end_date - pd.Timedelta(days=6)
        elif period_select == "14 derniers jours":
            start_date = end_date - pd.Timedelta(days=13)
        elif period_select == "30 derniers jours":
            start_date = end_date - pd.Timedelta(days=29)
        elif period_select == "Mois en cours":
            start_date = pd.Timestamp(end_date.year, end_date.month, 1)
        else:
            start_date = pd.Timestamp(date_range[0])

        before = len(filtered)
        filtered = filtered[(filtered['date'] >= start_date) & (filtered['date'] <= end_date)]
        print(f"   ‚úÖ Apr√®s filtre p√©riode ({start_date.date()} √† {end_date.date()}): {before} ‚Üí {len(filtered)} lignes")

    # ===== STATS FINALES =====
    print(f"\n   üìä R√âSULTAT FINAL:")
    print(f"   - Lignes finales: {len(filtered)}")
    if 'campaign_name' in filtered.columns:
        print(f"   - Campagnes uniques: {filtered['campaign_name'].nunique()}")
        print(f"   - Liste campagnes: {filtered['campaign_name'].unique().tolist()[:10]}")
    if 'cost' in filtered.columns:
        print(f"   - Co√ªt total: {filtered['cost'].sum():.2f}‚Ç¨")
    if 'installs' in filtered.columns:
        print(f"   - Installs totales: {filtered['installs'].sum():.0f}")
    if 'revenue' in filtered.columns:
        print(f"   - Revenue total: {filtered['revenue'].sum():.2f}‚Ç¨")

    return filtered


# ===== TOUTES VOS AUTRES FONCTIONS EXISTANTES =====
def _prepare_daily_data(data: pd.DataFrame) -> pd.DataFrame:
    """Pr√©pare les donn√©es pour l'analyse temporelle"""
    try:
        if 'date' not in data.columns:
            st.error("Colonne 'date' manquante dans les donn√©es")
            return pd.DataFrame()

        if data['date'].dtype == 'object':
            data['date'] = pd.to_datetime(data['date'])

        daily_data = data.groupby('date').agg({
            'cost': 'sum',
            'impressions': 'sum',
            'clicks': 'sum',
            'installs': 'sum',
            'purchases': 'sum',
            'revenue': 'sum',
            'opens': 'sum',
            'login': 'sum'
        }).reset_index()

        daily_data = daily_data.sort_values('date')

        daily_data['ctr'] = (daily_data['clicks'] / daily_data['impressions'] * 100).fillna(0)
        daily_data['conversion_rate'] = (daily_data['installs'] / daily_data['clicks'] * 100).fillna(0)
        daily_data['purchase_rate'] = (daily_data['purchases'] / daily_data['installs'] * 100).fillna(0)
        daily_data['roas'] = (daily_data['revenue'] / daily_data['cost']).fillna(0)

        return daily_data

    except Exception as e:
        st.error(f"Erreur lors de la pr√©paration des donn√©es: {e}")
        return pd.DataFrame()


def _create_line_chart(daily_data: pd.DataFrame, metrics: List[str], show_trend: bool) -> go.Figure:
    """Cr√©e un graphique en lignes"""

    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=('Co√ªt et Revenus', 'Trafic (Impressions/Clics)', 'Conversions', 'M√©triques de Performance'),
        specs=[[{"secondary_y": True}, {"secondary_y": True}],
               [{"secondary_y": True}, {"secondary_y": True}]]
    )

    colors = {
        'cost': '#e74c3c',
        'revenue': '#27ae60',
        'impressions': '#3498db',
        'clicks': '#2ecc71',
        'installs': '#9b59b6',
        'purchases': '#f39c12',
        'opens': '#1abc9c',
        'login': '#e67e22'
    }

    # Graphique 1: Co√ªt et Revenus
    if 'cost' in metrics and 'cost' in daily_data.columns:
        fig.add_trace(
            go.Scatter(x=daily_data['date'], y=daily_data['cost'],
                       name='Co√ªt', line=dict(color=colors['cost'])),
            row=1, col=1
        )

    if 'revenue' in metrics and 'revenue' in daily_data.columns:
        fig.add_trace(
            go.Scatter(x=daily_data['date'], y=daily_data['revenue'],
                       name='Revenus', line=dict(color=colors['revenue'])),
            row=1, col=1, secondary_y=True
        )

    # Graphique 2: Trafic
    if 'impressions' in metrics and 'impressions' in daily_data.columns:
        fig.add_trace(
            go.Scatter(x=daily_data['date'], y=daily_data['impressions'],
                       name='Impressions', line=dict(color=colors['impressions'])),
            row=1, col=2
        )

    if 'clicks' in metrics and 'clicks' in daily_data.columns:
        fig.add_trace(
            go.Scatter(x=daily_data['date'], y=daily_data['clicks'],
                       name='Clics', line=dict(color=colors['clicks'])),
            row=1, col=2, secondary_y=True
        )

    # Graphique 3: Conversions
    if 'installs' in metrics and 'installs' in daily_data.columns:
        fig.add_trace(
            go.Scatter(x=daily_data['date'], y=daily_data['installs'],
                       name='Installations', line=dict(color=colors['installs'])),
            row=2, col=1
        )

    if 'purchases' in metrics and 'purchases' in daily_data.columns:
        fig.add_trace(
            go.Scatter(x=daily_data['date'], y=daily_data['purchases'],
                       name='Achats', line=dict(color=colors['purchases'])),
            row=2, col=1, secondary_y=True
        )

    # Graphique 4: M√©triques de performance
    fig.add_trace(
        go.Scatter(x=daily_data['date'], y=daily_data['ctr'],
                   name='CTR (%)', line=dict(color='#34495e')),
        row=2, col=2
    )

    fig.add_trace(
        go.Scatter(x=daily_data['date'], y=daily_data['conversion_rate'],
                   name='Taux Conv. (%)', line=dict(color='#95a5a6')),
        row=2, col=2, secondary_y=True
    )

    # Ajout des lignes de tendance si demand√©
    if show_trend:
        _add_trend_lines(fig, daily_data, metrics)

    fig.update_layout(
        height=800,
        showlegend=True,
        title="√âvolution des Performances par Jour"
    )

    return fig


def _create_bar_chart(daily_data: pd.DataFrame, metrics: List[str]) -> go.Figure:
    """Cr√©e un graphique en barres"""

    fig = go.Figure()

    colors = {
        'cost': '#e74c3c',
        'revenue': '#27ae60',
        'impressions': '#3498db',
        'clicks': '#2ecc71',
        'installs': '#9b59b6',
        'purchases': '#f39c12'
    }

    for metric in metrics:
        if metric in daily_data.columns:
            fig.add_trace(go.Bar(
                x=daily_data['date'],
                y=daily_data[metric],
                name=metric.capitalize(),
                marker_color=colors.get(metric, '#7f8c8d')
            ))

    fig.update_layout(
        title="Performances Journali√®res - Vue en Barres",
        xaxis_title="Date",
        yaxis_title="Valeurs",
        height=500,
        barmode='group'
    )

    return fig


def _create_area_chart(daily_data: pd.DataFrame, metrics: List[str]) -> go.Figure:
    """Cr√©e un graphique en aires empil√©es"""

    fig = go.Figure()

    colors = ['#3498db', '#2ecc71', '#f39c12', '#e74c3c', '#9b59b6', '#1abc9c']

    for i, metric in enumerate(metrics):
        if metric in daily_data.columns:
            fig.add_trace(go.Scatter(
                x=daily_data['date'],
                y=daily_data[metric],
                mode='lines',
                stackgroup='one',
                name=metric.capitalize(),
                fill='tonexty' if i > 0 else 'tozeroy',
                line=dict(color=colors[i % len(colors)])
            ))

    fig.update_layout(
        title="Performances Journali√®res - Aires Empil√©es",
        xaxis_title="Date",
        yaxis_title="Valeurs",
        height=500
    )

    return fig


def _add_trend_lines(fig: go.Figure, daily_data: pd.DataFrame, metrics: List[str]):
    """Ajoute des lignes de tendance aux graphiques"""

    import numpy as np
    try:
        from scipy import stats

        x_numeric = list(range(len(daily_data)))

        for metric in ['cost', 'installs']:
            if metric in metrics and metric in daily_data.columns:
                y = daily_data[metric].values
                slope, intercept, r_value, p_value, std_err = stats.linregress(x_numeric, y)
                trend_line = [slope * x + intercept for x in x_numeric]

                # Ajouter la ligne de tendance (exemple pour le premier graphique)
                fig.add_trace(
                    go.Scatter(
                        x=daily_data['date'],
                        y=trend_line,
                        mode='lines',
                        name=f'Tendance {metric}',
                        line=dict(dash='dash', width=2),
                        showlegend=False
                    ),
                    row=1, col=1
                )
    except ImportError:
        # Si scipy n'est pas disponible, passer
        pass
    except Exception:
        # En cas d'erreur, continuer sans tendance
        pass


def _render_temporal_metrics(daily_data: pd.DataFrame):
    """Affiche les m√©triques de performance temporelle"""

    st.markdown("### üìà M√©triques Temporelles")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        # Moyenne mobile 7 jours
        if len(daily_data) >= 7:
            recent_avg_cost = daily_data['cost'].tail(7).mean()
            st.metric(
                "Co√ªt moyen (7j)",
                f"{recent_avg_cost:.2f}‚Ç¨",
                help="Moyenne mobile sur 7 jours"
            )

    with col2:
        # Croissance jour-√†-jour
        if len(daily_data) >= 2:
            last_installs = daily_data['installs'].iloc[-1]
            prev_installs = daily_data['installs'].iloc[-2]
            growth = ((last_installs - prev_installs) / prev_installs * 100) if prev_installs > 0 else 0

            st.metric(
                "Croissance installs",
                f"{growth:+.1f}%",
                help="Croissance jour-√†-jour"
            )

    with col3:
        # Meilleur jour
        if 'installs' in daily_data.columns:
            best_day_idx = daily_data['installs'].idxmax()
            best_day = daily_data.loc[best_day_idx, 'date']
            best_installs = daily_data.loc[best_day_idx, 'installs']

            st.metric(
                "Meilleur jour",
                f"{best_installs:.0f} installs",
                help=f"Le {best_day.strftime('%d/%m/%Y')}"
            )

    with col4:
        # Volatilit√©
        if len(daily_data) > 1:
            cost_volatility = daily_data['cost'].std() / daily_data['cost'].mean() * 100
            st.metric(
                "Volatilit√© co√ªt",
                f"{cost_volatility:.1f}%",
                help="Coefficient de variation du co√ªt"
            )


def _render_trend_analysis(daily_data: pd.DataFrame, metrics: List[str]):
    """Analyse des tendances"""

    st.markdown("### üîç Analyse des Tendances")

    if len(daily_data) < 3:
        st.info("Donn√©es insuffisantes pour l'analyse des tendances")
        return

    # Calcul des tendances simples
    trends = {}

    for metric in metrics:
        if metric in daily_data.columns and len(daily_data) >= 3:
            values = daily_data[metric].values

            # Tendance simple (comparaison premi√®re moiti√© vs deuxi√®me moiti√©)
            mid_point = len(values) // 2
            first_half = values[:mid_point].mean()
            second_half = values[mid_point:].mean()

            if first_half > 0:
                trend_pct = ((second_half - first_half) / first_half) * 100
                trends[metric] = {
                    'value': trend_pct,
                    'direction': 'üìà' if trend_pct > 5 else 'üìâ' if trend_pct < -5 else '‚û°Ô∏è'
                }

    # Affichage des tendances
    if trends:
        cols = st.columns(len(trends))
        for i, (metric, trend_data) in enumerate(trends.items()):
            with cols[i]:
                st.metric(
                    f"{trend_data['direction']} {metric.capitalize()}",
                    f"{trend_data['value']:+.1f}%",
                    help=f"Tendance sur la p√©riode"
                )

    # Insights automatiques
    _render_temporal_insights(daily_data, trends)


def _render_temporal_insights(daily_data: pd.DataFrame, trends: Dict):
    """G√©n√®re des insights temporels automatiques"""

    st.markdown("### üí° Insights Temporels")

    insights = []

    # Analyse des weekends vs semaine
    if len(daily_data) >= 7:
        daily_data['day_of_week'] = daily_data['date'].dt.dayofweek
        daily_data['is_weekend'] = daily_data['day_of_week'] >= 5

        weekend_avg = daily_data[daily_data['is_weekend']]['installs'].mean()
        weekday_avg = daily_data[~daily_data['is_weekend']]['installs'].mean()

        if weekend_avg > weekday_avg * 1.2:
            insights.append({
                'type': 'info',
                'title': 'Performance weekend',
                'message': f"Les weekends performent {((weekend_avg / weekday_avg - 1) * 100):.0f}% mieux que la semaine"
            })
        elif weekday_avg > weekend_avg * 1.2:
            insights.append({
                'type': 'info',
                'title': 'Performance semaine',
                'message': f"La semaine performe {((weekday_avg / weekend_avg - 1) * 100):.0f}% mieux que les weekends"
            })

    # Analyse des tendances
    for metric, trend_data in trends.items():
        if abs(trend_data['value']) > 20:
            trend_type = 'positive' if trend_data['value'] > 0 else 'warning'
            insights.append({
                'type': trend_type,
                'title': f'Tendance {metric}',
                'message': f"√âvolution de {trend_data['value']:+.1f}% sur la p√©riode"
            })

    # D√©tection de pics/creux
    if 'cost' in daily_data.columns:
        cost_max_day = daily_data.loc[daily_data['cost'].idxmax()]
        cost_max = cost_max_day['cost']
        cost_avg = daily_data['cost'].mean()

        if cost_max > cost_avg * 2:
            insights.append({
                'type': 'warning',
                'title': 'Pic de co√ªt d√©tect√©',
                'message': f"Le {cost_max_day['date'].strftime('%d/%m')} : {cost_max:.0f}‚Ç¨ (vs {cost_avg:.0f}‚Ç¨ en moyenne)"
            })

    # Affichage des insights
    if insights:
        for insight in insights:
            if insight['type'] == 'positive':
                st.success(f"‚úÖ **{insight['title']}**: {insight['message']}")
            elif insight['type'] == 'warning':
                st.warning(f"‚ö†Ô∏è **{insight['title']}**: {insight['message']}")
            else:
                st.info(f"‚ÑπÔ∏è **{insight['title']}**: {insight['message']}")
    else:
        st.info("üìä Performances stables sur la p√©riode analys√©e")


def render_weekly_summary(data: pd.DataFrame):
    """Affiche un r√©sum√© hebdomadaire"""

    st.markdown("### üìÖ R√©sum√© Hebdomadaire")

    if data.empty:
        st.info("Aucune donn√©e pour le r√©sum√© hebdomadaire")
        return

    # Conversion en semaines
    data_copy = data.copy()
    data_copy['date'] = pd.to_datetime(data_copy['date'])
    data_copy['week'] = data_copy['date'].dt.isocalendar().week
    data_copy['year'] = data_copy['date'].dt.year
    data_copy['week_label'] = data_copy['year'].astype(str) + '-S' + data_copy['week'].astype(str)

    # Agr√©gation par semaine
    weekly_data = data_copy.groupby('week_label').agg({
        'cost': 'sum',
        'installs': 'sum',
        'purchases': 'sum',
        'revenue': 'sum'
    }).reset_index()

    # Calcul des m√©triques hebdomadaires
    weekly_data['cpa'] = weekly_data['cost'] / weekly_data['installs']
    weekly_data['roas'] = weekly_data['revenue'] / weekly_data['cost']
    weekly_data['cpa'] = weekly_data['cpa'].fillna(0)
    weekly_data['roas'] = weekly_data['roas'].fillna(0)

    # Affichage du tableau
    st.dataframe(
        weekly_data,
        column_config={
            "week_label": "Semaine",
            "cost": st.column_config.NumberColumn("Co√ªt", format="%.2f ‚Ç¨"),
            "installs": st.column_config.NumberColumn("Installs", format="%d"),
            "purchases": st.column_config.NumberColumn("Achats", format="%d"),
            "revenue": st.column_config.NumberColumn("Revenus", format="%.2f ‚Ç¨"),
            "cpa": st.column_config.NumberColumn("CPA", format="%.2f ‚Ç¨"),
            "roas": st.column_config.NumberColumn("ROAS", format="%.2f")
        },
        use_container_width=True
    )